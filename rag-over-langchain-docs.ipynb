{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"6L1YrG1mfbF8","outputId":"14fd8bd5-c0bb-4c80-98a6-37515229040f"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","langchain-openai 0.1.6 requires langchain-core<0.2.0,>=0.1.46, but you have langchain-core 0.2.10 which is incompatible.\n","langchain-experimental 0.0.62 requires langchain-community<0.3.0,>=0.2.6, but you have langchain-community 0.0.20 which is incompatible.\n","langchain-community 0.0.20 requires langchain-core<0.2,>=0.1.21, but you have langchain-core 0.2.10 which is incompatible.\n","langchain-community 0.0.20 requires langsmith<0.1,>=0.0.83, but you have langsmith 0.1.82 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install -U --quiet langchain langsmith langchainhub langchain_benchmarks\n","%pip install --quiet chromadb openai huggingface pandas langchain_experimental sentence_transformers pyarrow anthropic tiktoken"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-19IjYhVfbF_"},"outputs":[],"source":["import os\n","\n","os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n","os.environ[\"LANGCHAIN_API_KEY\"] = \"LANGCHAIN_API_KEY_HERE\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jxxsRRpTfbF_"},"outputs":[],"source":["# Update these with your own API keys\n","os.environ[\"ANTHROPIC_API_KEY\"] = \"ANTHROPIC_API_KEY_HERE\"\n","os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY_HERE\"\n","# Silence warnings from HuggingFace\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n-WUXChFfbGA"},"outputs":[],"source":["import uuid\n","\n","# Generate a unique run ID for this experiment\n","run_uid = uuid.uuid4().hex[:6]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N1-VDOfUfbGA"},"outputs":[],"source":["from langchain_benchmarks import clone_public_dataset, registry\n","from langsmith import traceable"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"68VxL0b6fbGA","outputId":"b962b60d-8920-47f8-bef9-f601b074eb40"},"outputs":[{"data":{"text/html":["<table>\n","<thead>\n","<tr><th>Name                   </th><th>Type         </th><th>Dataset ID                                                                                                                                                 </th><th>Description  </th></tr>\n","</thead>\n","<tbody>\n","<tr><td>LangChain Docs Q&A     </td><td>RetrievalTask</td><td><a href=\"https://smith.langchain.com/public/452ccafc-18e1-4314-885b-edd735f17b9d/d\" target=\"_blank\" rel=\"noopener\">452ccafc-18e1-4314-885b-edd735f17b9d</a></td><td>Questions and answers based on a snapshot of the LangChain python docs.\n","\n","The environment provides the documents and the retriever information.\n","\n","Each example is composed of a question and reference answer.\n","\n","Success is measured based on the accuracy of the answer relative to the reference answer.\n","We also measure the faithfulness of the model's response relative to the retrieved documents (if any).              </td></tr>\n","<tr><td>Semi-structured Reports</td><td>RetrievalTask</td><td><a href=\"https://smith.langchain.com/public/c47d9617-ab99-4d6e-a6e6-92b8daf85a7d/d\" target=\"_blank\" rel=\"noopener\">c47d9617-ab99-4d6e-a6e6-92b8daf85a7d</a></td><td>Questions and answers based on PDFs containing tables and charts.\n","\n","The task provides the raw documents as well as factory methods to easily index them\n","and create a retriever.\n","\n","Each example is composed of a question and reference answer.\n","\n","Success is measured based on the accuracy of the answer relative to the reference answer.\n","We also measure the faithfulness of the model's response relative to the retrieved documents (if any).              </td></tr>\n","<tr><td>Multi-modal slide decks</td><td>RetrievalTask</td><td><a href=\"https://smith.langchain.com/public/40afc8e7-9d7e-44ed-8971-2cae1eb59731/d\" target=\"_blank\" rel=\"noopener\">40afc8e7-9d7e-44ed-8971-2cae1eb59731</a></td><td>This public dataset is a work-in-progress and will be extended over time.\n","        \n","Questions and answers based on slide decks containing visual tables and charts.\n","\n","Each example is composed of a question and reference answer.\n","\n","Success is measured based on the accuracy of the answer relative to the reference answer.              </td></tr>\n","</tbody>\n","</table>"],"text/plain":["Registry(tasks=[RetrievalTask(name='LangChain Docs Q&A', dataset_id='https://smith.langchain.com/public/452ccafc-18e1-4314-885b-edd735f17b9d/d', description=\"Questions and answers based on a snapshot of the LangChain python docs.\\n\\nThe environment provides the documents and the retriever information.\\n\\nEach example is composed of a question and reference answer.\\n\\nSuccess is measured based on the accuracy of the answer relative to the reference answer.\\nWe also measure the faithfulness of the model's response relative to the retrieved documents (if any).\\n\", get_docs=<function load_cached_docs at 0x762cda99f9a0>, retriever_factories={'basic': <function _chroma_retriever_factory at 0x762cd9b8d1b0>, 'parent-doc': <function _chroma_parent_document_retriever_factory at 0x762cd9b8d240>, 'hyde': <function _chroma_hyde_retriever_factory at 0x762cd9b8d2d0>}, architecture_factories={'conversational-retrieval-qa': <function default_response_chain at 0x762cda99fb50>}), RetrievalTask(name='Semi-structured Reports', dataset_id='https://smith.langchain.com/public/c47d9617-ab99-4d6e-a6e6-92b8daf85a7d/d', description=\"Questions and answers based on PDFs containing tables and charts.\\n\\nThe task provides the raw documents as well as factory methods to easily index them\\nand create a retriever.\\n\\nEach example is composed of a question and reference answer.\\n\\nSuccess is measured based on the accuracy of the answer relative to the reference answer.\\nWe also measure the faithfulness of the model's response relative to the retrieved documents (if any).\\n\", get_docs=<function load_docs at 0x762cd9b8d990>, retriever_factories={'basic': <function _chroma_retriever_factory at 0x762cd9b8dab0>, 'parent-doc': <function _chroma_parent_document_retriever_factory at 0x762cd9b8db40>, 'hyde': <function _chroma_hyde_retriever_factory at 0x762cd9b8dbd0>}, architecture_factories={}), RetrievalTask(name='Multi-modal slide decks', dataset_id='https://smith.langchain.com/public/40afc8e7-9d7e-44ed-8971-2cae1eb59731/d', description='This public dataset is a work-in-progress and will be extended over time.\\n        \\nQuestions and answers based on slide decks containing visual tables and charts.\\n\\nEach example is composed of a question and reference answer.\\n\\nSuccess is measured based on the accuracy of the answer relative to the reference answer.\\n', get_docs={}, retriever_factories={}, architecture_factories={})])"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["registry = registry.filter(Type=\"RetrievalTask\")\n","registry"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u8JCvHFZfbGA","outputId":"e7ebbf4d-f150-4242-a71c-6ae9c02cd6a2"},"outputs":[{"data":{"text/html":["<table>\n","<tbody>\n","<tr><td>Name                  </td><td>LangChain Docs Q&A                                                                                                                                         </td></tr>\n","<tr><td>Type                  </td><td>RetrievalTask                                                                                                                                              </td></tr>\n","<tr><td>Dataset ID            </td><td><a href=\"https://smith.langchain.com/public/452ccafc-18e1-4314-885b-edd735f17b9d/d\" target=\"_blank\" rel=\"noopener\">452ccafc-18e1-4314-885b-edd735f17b9d</a></td></tr>\n","<tr><td>Description           </td><td>Questions and answers based on a snapshot of the LangChain python docs.\n","\n","The environment provides the documents and the retriever information.\n","\n","Each example is composed of a question and reference answer.\n","\n","Success is measured based on the accuracy of the answer relative to the reference answer.\n","We also measure the faithfulness of the model's response relative to the retrieved documents (if any).                                                                                                                                                            </td></tr>\n","<tr><td>Retriever Factories   </td><td>basic, parent-doc, hyde                                                                                                                                    </td></tr>\n","<tr><td>Architecture Factories</td><td>conversational-retrieval-qa                                                                                                                                </td></tr>\n","<tr><td>get_docs              </td><td><function load_cached_docs at 0x762cda99f9a0>                                                                                                              </td></tr>\n","</tbody>\n","</table>"],"text/plain":["RetrievalTask(name='LangChain Docs Q&A', dataset_id='https://smith.langchain.com/public/452ccafc-18e1-4314-885b-edd735f17b9d/d', description=\"Questions and answers based on a snapshot of the LangChain python docs.\\n\\nThe environment provides the documents and the retriever information.\\n\\nEach example is composed of a question and reference answer.\\n\\nSuccess is measured based on the accuracy of the answer relative to the reference answer.\\nWe also measure the faithfulness of the model's response relative to the retrieved documents (if any).\\n\", get_docs=<function load_cached_docs at 0x762cda99f9a0>, retriever_factories={'basic': <function _chroma_retriever_factory at 0x762cd9b8d1b0>, 'parent-doc': <function _chroma_parent_document_retriever_factory at 0x762cd9b8d240>, 'hyde': <function _chroma_hyde_retriever_factory at 0x762cd9b8d2d0>}, architecture_factories={'conversational-retrieval-qa': <function default_response_chain at 0x762cda99fb50>})"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["langchain_docs = registry[\"LangChain Docs Q&A\"]\n","langchain_docs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oAtbXlhIfbGB","outputId":"521ad781-b631-4f3e-a250-11627061d793"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset LangChain Docs Q&A already exists. Skipping.\n","You can access the dataset at https://smith.langchain.com/o/c9534f73-04c8-5644-b464-e311feca6a81/datasets/ec76a09e-14d8-44c5-bced-7e1bbe582546.\n"]}],"source":["@traceable\n","def langchain_docs_query(question: str):\n","    return langchain_docs.query(question)\n","clone_public_dataset(langchain_docs.dataset_id,\n","                     dataset_name=langchain_docs.name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bTZO9_PIfbGB","outputId":"1dd04ef3-dca0-44ff-962d-3b487399ba92"},"outputs":[{"name":"stdout","output_type":"stream","text":["Document(page_content=\"LangChain cookbook | ðŸ¦œï¸ðŸ”— Langchain\\n\\n[Skip to main content](#docusaurus_skip...\n"]}],"source":["docs = list(langchain_docs.get_docs())\n","print(repr(docs[0])[:100] + \"...\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FgtqsPJqfbGB","outputId":"4a11f6b8-efc0-4134-b7f6-e243111b22fb"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/akilesh/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n","  warn_deprecated(\n","/home/akilesh/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]}],"source":["from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.vectorstores.chroma import Chroma\n","\n","embeddings = HuggingFaceEmbeddings(\n","    model_name=\"thenlper/gte-base\",\n","    # model_kwargs={\"device\": 0},  # Comment out to use CPU\n",")\n","\n","vectorstore = Chroma(\n","    collection_name=\"lcbm-b-huggingface-gte-base\",\n","    embedding_function=embeddings,\n","    persist_directory=\"./chromadb\",\n",")\n","\n","vectorstore.add_documents(docs)\n","retriever = vectorstore.as_retriever(search_kwargs={\"k\": 6})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W16PIFF9fbGB","outputId":"701a7d06-e6bf-4824-d6c0-af5f3c8f0091"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/akilesh/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n","  warn_deprecated(\n"]}],"source":["from operator import itemgetter\n","from typing import Sequence\n","\n","from langchain.chat_models import ChatOpenAI\n","from langchain.prompts import ChatPromptTemplate\n","from langchain.schema.document import Document\n","from langchain.schema.output_parser import StrOutputParser\n","from langchain.schema.runnable.passthrough import RunnableAssign\n","\n","\n","# After the retriever fetches documents, this\n","# function formats them in a string to present for the LLM\n","@traceable\n","def format_docs(docs: Sequence[Document]) -> str:\n","    formatted_docs = []\n","    for i, doc in enumerate(docs):\n","        doc_string = (\n","            f\"<document index='{i}'>\\n\"\n","            f\"<source>{doc.metadata.get('source')}</source>\\n\"\n","            f\"<doc_content>{doc.page_content}</doc_content>\\n\"\n","            \"</document>\"\n","        )\n","        formatted_docs.append(doc_string)\n","    formatted_str = \"\\n\".join(formatted_docs)\n","    return f\"<documents>\\n{formatted_str}\\n</documents>\"\n","\n","\n","prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"You are an AI assistant answering questions about LangChain.\"\n","            \"\\n{context}\\n\"\n","            \"Respond solely based on the document content.\",\n","        ),\n","        (\"human\", \"{question}\"),\n","    ]\n",")\n","llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=1)\n","\n","response_generator = (prompt | llm | StrOutputParser()).with_config(\n","    run_name=\"GenerateResponse\",\n",")\n","\n","# This is the final response chain.\n","# It fetches the \"question\" key from the input dict,\n","# passes it to the retriever, then formats as a string.\n","\n","chain = (\n","    RunnableAssign(\n","        {\n","            \"context\": (itemgetter(\"question\") | retriever | format_docs).with_config(\n","                run_name=\"FormatDocs\"\n","            )\n","        }\n","    )\n","    # The \"RunnableAssign\" above returns a dict with keys\n","    # question (from the original input) and\n","    # context: the string-formatted docs.\n","    # This is passed to the response_generator above\n","    | response_generator\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pgny3jxWfbGB","outputId":"2b57521f-acdd-4534-86d5-c075ac0dfe0f"},"outputs":[{"data":{"text/plain":["'A chain in LangChain is a sequence of operations executed in response to an input. It consists of a series of customizable components (such as language models, memory stores, and callbacks) that work together to generate outputs. Chains in LangChain can be used for various tasks, such as having a conversation, loading context from memory, and more, making them versatile and powerful tools for building AI workflows.'"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["chain.invoke({\"question\": \"Tell me how a chain works in LangChain. In 3 sentences.\"})"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}